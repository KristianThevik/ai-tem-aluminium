{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Strength Model\n",
    "This code uses the Holmedal model to calculate the total yield strength of an aluminium alloy condition.\n",
    "This strength model is here used on alloy condition VAR3_NA_5h_185C from SumAL project. The measured Vickers Hardness was measued experimentally to be 130.8 MPa. The model calculates and predicts 134.6 MPa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.optimize import least_squares\n",
    "from scipy import special\n",
    "from scipy.integrate import quad\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = 2       # Pinning force parameter\n",
    "M = 2.7         # Taylor factor\n",
    "G = 27E3        # [MPa] Shear modulus Al matrix\n",
    "b = 0.286       # [nm] Burgers vector Al, b = a/sqrt(2)\n",
    "alpha_p = 0.9   # Scaling factor. Should ideally through calibration\n",
    "t = 59.447125          # [nm] Sample thickness, HAS TO BE GIVEN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "First run the percipitate statistics models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2515\n",
      "21.59\n",
      "384\n",
      "11.78\n",
      "0.0009454\n"
     ]
    }
   ],
   "source": [
    "lengths_file = \"statistics_lengths.csv\"\n",
    "df_length = pd.read_csv(lengths_file)\n",
    "length_col = [col for col in df_length.columns if \"Length\" in col]\n",
    "precipitate_lengths = df_length[length_col[0]].dropna().tolist()\n",
    "mean_col_l = [col for col in df_length.columns if \"Average\" in col]\n",
    "mean_length = df_length[mean_col_l[0]].dropna().iloc[0]\n",
    "print(len(precipitate_lengths))\n",
    "print(mean_length)\n",
    "\n",
    "\n",
    "cross_section_file = \"statistics_cross.csv\"\n",
    "df_cross = pd.read_csv(cross_section_file)\n",
    "cross_col = [col for col in df_cross.columns if \"Cross section\" in col]\n",
    "precipitate_cross = df_cross[cross_col[0]].dropna().tolist()\n",
    "mean_col_c = [col for col in df_cross.columns if \"Average\" in col]\n",
    "mean_cross = df_cross[mean_col_c[0]].dropna().iloc[0]\n",
    "print(len(precipitate_cross))\n",
    "print(mean_cross)\n",
    "\n",
    "\n",
    "dark_field_file = \"statistics_df.csv\"\n",
    "df_cross_dark = pd.read_csv(dark_field_file)\n",
    "density_col = [col for col in df_cross_dark.columns if \"Number Density [nm^-2]\" in col]\n",
    "number_density = df_cross_dark[density_col[0]].dropna().iloc[0]\n",
    "print(number_density) # Number density is here the average N/A, the average number of \n",
    "# precipitates counted in an image divided by area of the image\n",
    "\n",
    "crit_cs = mean_cross\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2D_to_3D_number_density(N_per_A, t, mean_length):\n",
    "    \"\"\"\n",
    "    Converts 2D number density (precipitates per nm²) into 3D number density (precipitates per nm³).\n",
    "\n",
    "    Parameters:\n",
    "    N_per_A (float): Precipitate count per unit area [#/nm²] over all images of alloy conditon.\n",
    "    t (float): Sample thickness [nm].\n",
    "    l_mean (float): Mean precipitate length [nm].\n",
    "\n",
    "    Returns:\n",
    "    float: 3D number density [#/nm³].\n",
    "    \"\"\"\n",
    "    return (3 * N_per_A) / (t * (1 + (mean_length / t)))\n",
    "\n",
    "def calculate_volume_fraction(rho, mean_cross, mean_length):\n",
    "    \"\"\"\n",
    "    Computes the precipitate volume fraction.\n",
    "\n",
    "    Parameters:\n",
    "    rho (float): Precipitate number density [#/nm³].\n",
    "    a_mean (float): Mean precipitate cross-sectional area [nm²].\n",
    "    l_mean (float): Mean precipitate length [nm].\n",
    "\n",
    "    Returns:\n",
    "    float: Volume fraction f_V in precentage.\n",
    "    \"\"\"\n",
    "    return rho * mean_cross * mean_length *100\n",
    "\n",
    "\n",
    "\n",
    "def omega(x: list, l):\n",
    "    \"\"\"\n",
    "    Computes the aspect ratio function, modeled using a power law:\n",
    "\n",
    "        Ω(l) = a * l^b\n",
    "\n",
    "    where:\n",
    "        - Ω(l) is the aspect ratio of the precipitate.\n",
    "        - 'a' (x[0]) is the scaling factor.\n",
    "        - 'b' (x[1]) is the exponent.\n",
    "        - 'l' is the precipitate length (scalar or array).\n",
    "\n",
    "    The theoretical aspect ratio for a cylindrical precipitate is:\n",
    "\n",
    "        Ω = l / sqrt(A)\n",
    "\n",
    "    Instead of using this directly, we approximate the aspect ratio using a power-law function.\n",
    "\n",
    "    To avoid values below 1, we enforce Ω(l) ≥ 1.\n",
    "    \"\"\"\n",
    "    arr = x[0] * np.power(l, x[1])  # Compute the power law function\n",
    "\n",
    "    # Ensure all values in arr are at least 1\n",
    "    if isinstance(arr, np.ndarray):  \n",
    "        arr[arr < 1] = 1  \n",
    "    else:  \n",
    "        arr = max(arr, 1)  # Ensures scalars do not fall below 1\n",
    "\n",
    "    return arr\n",
    "\n",
    "def fit_omega(l, aspect_ratio):\n",
    "    \"\"\"\n",
    "    Finds the best fit for the aspect ratio function Ω(l) = a * l^b.\n",
    "    \n",
    "    l: Array of measured precipitate lengths\n",
    "    aspect_ratio: Corresponding measured aspect ratios (l / sqrt(A))?\n",
    "\n",
    "    Returns optimized values of a and b.\n",
    "    \"\"\"\n",
    "    x0_fit = [0.7, 0.7]  # Initial guess for parameters (a, b)\n",
    "    residual = lambda x: aspect_ratio - omega(x, l)  # Residual function\n",
    "    result = least_squares(residual, x0_fit)  # Perform least-squares optimization\n",
    "    return result.x  # Return fitted parameters\n",
    "\n",
    "def f(a, a_c, kappa):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        a     : Precipitate cross-section [nm²]\n",
    "        a_c   : Critical cross-section defining transition between \n",
    "                shearable and non-shearable precipitates [nm²]\n",
    "        kappa : Exponent controlling scaling behavior\n",
    "\n",
    "    Output:\n",
    "        f     : Obstacle length\n",
    "    \"\"\"\n",
    "    return np.min([(a / a_c) ** kappa, 1])\n",
    "\n",
    "def tau_p(alpha_p, G, b, n_p, f_bar):\n",
    "    \"\"\"\n",
    "    Strength contribution from precipitate-based obstacles.\n",
    "\n",
    "    Input:\n",
    "        alpha_p : Scaling factor\n",
    "        G       : Shear modulus [MPa]\n",
    "        b       : Burgers vector [nm]\n",
    "        n_p     : Number density of precipitate-based obstacles per slip plane [#/nm²]\n",
    "        f_bar   : Mean obstacle length (dimensionless)\n",
    "\n",
    "    Output:\n",
    "        tau_p   : Strength contribution from obstacles [MPa]\n",
    "    \"\"\"\n",
    "    return alpha_p * G * b * np.sqrt(n_p) * f_bar**(3/2) * (1 - 1/6 * f_bar**5)\n",
    "\n",
    "def phi_tilde(l: float, lengths_data: float, h: float):\n",
    "    \"\"\"\n",
    "    Uncorrected distribution of precipitate lengths.\n",
    "\n",
    "    Input:\n",
    "        l  : The length interval to evaluate the distribution of lengths at\n",
    "        lengths_data : Precipitate length data used to fit the distribution\n",
    "        h  : Kernel bandwidth for smoothing, determined using Scott's rule\n",
    "\n",
    "    Output:\n",
    "        Probability density at length l (before correction)\n",
    "    \"\"\"\n",
    "    return (1 / len(lengths_data)) * np.sum(\n",
    "    np.sqrt(2) * np.exp(-0.5 * ((np.full(len(lengths_data), l) - np.array(lengths_data)) / h) ** 2) /\n",
    "    ((1 + special.erf(np.array(lengths_data) / (np.sqrt(2) * h))) * h * np.sqrt(np.pi))\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def phi(l, length_data, h):\n",
    "    \"\"\"\n",
    "    Normalized precipitate length distribution.\n",
    "\n",
    "    This function corrects the unnormalized kernel density estimate \n",
    "    phi_tilde, ensuring that the precipitate length distribution meets \n",
    "    the required boundary condition, reaching zero at l = 0.\n",
    "\n",
    "    Input:\n",
    "        l           : The length interval to evaluate the distribution of lengths at\n",
    "        length_data : Array of measured precipitate lengths\n",
    "        h           : Kernel bandwidth for smoothing, determined using Scott's rule\n",
    "\n",
    "    Output:\n",
    "        phi         : Normalized probability density of precipitate lengths [1/nm]\n",
    "\n",
    "    \"\"\"\n",
    "    return (phi_tilde(l, length_data, h) - phi_tilde(0, length_data, h) * np.exp(-0.5 * (l / h) ** 2)) / \\\n",
    "           (1 - 0.5 * h * np.sqrt(2 * np.pi) * phi_tilde(0, length_data, h))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculated_kernel_bandwidth(length_data):\n",
    "    \"\"\"\n",
    "    Computes the kernel bandwidth (h) for a single experimental condition \n",
    "    using Scott's rule:\n",
    "\n",
    "        h ≈ d * N_l^(-0.2) * sigma_l\n",
    "\n",
    "    where:\n",
    "        - h      : Kernel bandwidth for KDE smoothing [nm]\n",
    "        - d      : Empirical scaling factor (0.8)\n",
    "        - N_l    : Number of measured precipitate lengths\n",
    "        - sigma_l: Standard deviation of precipitate lengths\n",
    "\n",
    "    Input:\n",
    "        length_data : List or array of measured precipitate length values.\n",
    "\n",
    "    Output:\n",
    "        h          : Calculated bandwidth (h) for the given condition.\n",
    "    \"\"\"\n",
    "    sigma = np.std(length_data)  # Compute standard deviation (σ_l)\n",
    "    N_l = len(length_data)       # Get number of data points (N_l)\n",
    "\n",
    "    # Apply Scott's rule: h = d * N_l^(-0.2) * σ_l\n",
    "    h = 0.8 * N_l**(-0.2) * sigma\n",
    "\n",
    "    return h  # Return the bandwidth value\n",
    "\n",
    "\n",
    "\n",
    "def shearable_precipitate_integrand(l, aspect_ratio_params, kappa, length_distribution):\n",
    "    \"\"\"\n",
    "    Computes the integrand for the shearable precipitate contribution.\n",
    "\n",
    "    Based on the integral term:\n",
    "        ∫ (l^(2κ+1) / Ω(l)^(2κ)) * φ(l) dl\n",
    "\n",
    "    where:\n",
    "        - l                   : Precipitate length [nm]\n",
    "        - aspect_ratio_params  : Parameters for the aspect ratio function Ω(l)\n",
    "        - kappa               : Scaling exponent for strength model\n",
    "        - length_distribution : Normalized precipitate length distribution φ(l)\n",
    "\n",
    "    Output:\n",
    "        Contribution of shearable precipitates to the mean obstacle strength.\n",
    "    \"\"\"\n",
    "    return (l**(2*kappa + 1) / omega(aspect_ratio_params, l)**(2*kappa)) * length_distribution(l)\n",
    "\n",
    "def non_shearable_precipitate_integrand(l, length_distribution):\n",
    "    \"\"\"\n",
    "    Computes the integrand for the non-shearable precipitate contribution.\n",
    "\n",
    "    Based on the integral term:\n",
    "        ∫ l * φ(l) dl\n",
    "\n",
    "    where:\n",
    "        - l                   : Precipitate length [nm]\n",
    "        - length_distribution : Normalized precipitate length distribution φ(l)\n",
    "\n",
    "    Output:\n",
    "        Contribution of non-shearable precipitates to the mean obstacle strength.\n",
    "    \"\"\"\n",
    "    return l * length_distribution(l)\n",
    "\n",
    "\n",
    "def convert_weight_to_atomic_fraction(weight_percent, atomic_weights, element):\n",
    "    \"\"\"\n",
    "    Convert weight percent (wt%) to atomic fraction (at%).\n",
    "\n",
    "    Input:\n",
    "        weight_percent  : Dictionary containing element weight fractions {Element: wt%}\n",
    "        atomic_weights  : Dictionary containing atomic weights {Element: atomic weight}\n",
    "        element         : Element to convert\n",
    "\n",
    "    Output:\n",
    "        atomic_fraction : Atomic fraction (at%) of the element\n",
    "    \"\"\"\n",
    "    return (weight_percent[element] / atomic_weights[element]) / \\\n",
    "           sum(weight_percent[el] / atomic_weights[el] for el in weight_percent if el in atomic_weights)\n",
    "\n",
    "\n",
    "def convert_atomic_to_weight_fraction(atomic_fraction_dict, atomic_weights, element):\n",
    "    \"\"\"\n",
    "    Convert atomic fraction (at%) to weight percent (wt%).\n",
    "\n",
    "    Input:\n",
    "        atomic_fraction_dict : Dictionary containing atomic fractions {Element: at%}\n",
    "        atomic_weights       : Dictionary containing atomic weights {Element: atomic weight}\n",
    "        element              : The specific element to convert\n",
    "\n",
    "    Output:\n",
    "        weight_percent       : Weight percent (wt%) of the specified element\n",
    "    \"\"\"\n",
    " \n",
    "\n",
    "    # Compute weight fraction using weight-to-atomic conversion for the denominator\n",
    "    return (atomic_fraction_dict[element] * atomic_weights[element]) / \\\n",
    "           sum(convert_weight_to_atomic_fraction(atomic_fraction_dict, atomic_weights, el) * atomic_weights[el] \n",
    "               for el in atomic_fraction_dict if el in atomic_weights)\n",
    "\n",
    "\n",
    "# Critical cross section is here just taken to be the mean cross section. It should be\n",
    "# the mean cross section at peak at the ageing condition near peak strength.\n",
    "def calculate_solid_solution_strength(alloy_composition, volume_fraction, atomic_weights, strengthening_coefficients):\n",
    "    \"\"\"\n",
    "    Computes the solid solution strengthening contribution from alloying elements.\n",
    "\n",
    "    Input:\n",
    "        alloy_composition         : Dictionary containing element weight fractions {Element: wt%}\n",
    "        volume_fraction           : Precipitate volume fraction (percentage, not decimal)\n",
    "        atomic_weights            : Dictionary containing atomic weights {Element: atomic weight}\n",
    "        strengthening_coefficients: Dictionary of strengthening coefficients {Element: MPa}\n",
    "\n",
    "    Output:\n",
    "        sigma_ss                  : Solid solution strengthening contribution [MPa]\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert volume fraction to solid fraction adjustment (22/24 factor)\n",
    "    solid_fraction = np.array(volume_fraction) * 22 / 24  \n",
    "    print(f\"Solid Fraction: {solid_fraction:.6f}%\")\n",
    "\n",
    "    # Ensure Al fraction is correct\n",
    "    alloy_composition['Al'] = 100 - sum(alloy_composition.values())\n",
    "\n",
    "    # Enforce Si content as done in Holmedal model (REMOVE if unnecessary)\n",
    "    alloy_composition['Si'] = 0.95\n",
    "\n",
    "    # Beta'' fraction assumptions\n",
    "    betaDP = {'Mg': 0.42, 'Si': 0.30, 'Cu': 0.03}  \n",
    "\n",
    "    # Compute fraction of each element going into β'' precipitates\n",
    "    precipitated_fractions = {\n",
    "        'Mg': betaDP['Mg'] * solid_fraction,\n",
    "        'Si': betaDP['Si'] * solid_fraction,\n",
    "        'Cu': betaDP['Cu'] * solid_fraction\n",
    "    }\n",
    "\n",
    "    # Compute weight percent remaining in solid solution\n",
    "    weight_mg = max(0, alloy_composition['Mg'] - convert_atomic_to_weight_fraction(precipitated_fractions, atomic_weights, 'Mg'))\n",
    "    weight_si = max(0, alloy_composition['Si'] - convert_atomic_to_weight_fraction(precipitated_fractions, atomic_weights, 'Si'))\n",
    "    weight_cu = max(0, alloy_composition['Cu'] - convert_atomic_to_weight_fraction(precipitated_fractions, atomic_weights, 'Cu'))\n",
    "\n",
    "    print(f\"Weight % in Solution - Mg: {weight_mg:.3f}, Si: {weight_si:.3f}, Cu: {weight_cu:.3f}\")\n",
    "\n",
    "    # Compute the solid solution strengthening using weight percent\n",
    "    sigma_ss = (\n",
    "        strengthening_coefficients['Mg'] * weight_mg**(2/3) +\n",
    "        strengthening_coefficients['Si'] * weight_si**(2/3) +\n",
    "        strengthening_coefficients['Cu'] * weight_cu**(2/3)\n",
    "    )\n",
    "\n",
    "    return sigma_ss  # Single scalar value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_yield_strength_single(precipitate_lengths, mean_length, mean_cross_section,\n",
    "                                    rho, aspect_ratio_params, critical_cross_section, \n",
    "                                    kappa, shear_modulus, burgers_vector, taylor_factor, \n",
    "                                    solid_solution_strength, base_strength,\n",
    "                                    omega_func, shearable_integrand, non_shearable_integrand):\n",
    "    \"\"\"\n",
    "    Computes the yield strength for a single alloy condition **without empirical calibration**.\n",
    "\n",
    "    Input:\n",
    "        precipitate_lengths      : List of precipitate lengths for the alloy condition [nm]\n",
    "        mean_length              : Mean precipitate length in this condition [nm]\n",
    "        mean_cross_section       : Mean precipitate cross-section in this condition [nm²]\n",
    "        rho                      : Number density of precipitates in this condition [#/nm³]\n",
    "        aspect_ratio_params      : Parameters for the aspect ratio function Ω(l)\n",
    "        critical_cross_section   : Critical cross-section a_c defining shearable/non-shearable transition [nm²]\n",
    "        kappa                   : Scaling exponent for strength model\n",
    "        shear_modulus            : Shear modulus G [MPa]\n",
    "        burgers_vector           : Burgers vector b [nm]\n",
    "        taylor_factor            : Taylor factor M (polycrystalline strengthening factor)\n",
    "        solid_solution_strength  : Solid solution strengthening contribution [MPa]\n",
    "        base_strength            : Baseline yield strength σ₀ [MPa]\n",
    "        omega_func               : Function to compute aspect ratio Ω(l)\n",
    "        shearable_integrand      : Function computing the integral for shearable precipitates\n",
    "        non_shearable_integrand  : Function computing the integral for non-shearable precipitates\n",
    "\n",
    "    Output:\n",
    "        yield_strength           : Computed yield strength [MPa]\n",
    "    \"\"\"\n",
    "\n",
    "    # Solve for the critical length l_c using least squares\n",
    "    residual_func = lambda l: np.sqrt(critical_cross_section) * omega_func(aspect_ratio_params, l) - l\n",
    "    critical_length = least_squares(residual_func, 16).x[0]  \n",
    "\n",
    "    # Compute kernel bandwidth for KDE smoothing\n",
    "    kernel_bandwidth = calculated_kernel_bandwidth(precipitate_lengths)\n",
    "\n",
    "    # Define phi with proper arguments so it can be used inside quad()\n",
    "    phi_function = lambda l: phi(l, precipitate_lengths, kernel_bandwidth)\n",
    "\n",
    "    # Compute mean obstacle strength f_bar\n",
    "    f_bar = (quad(shearable_integrand, 0, critical_length, args=(aspect_ratio_params, kappa, phi_function))[0] / (critical_cross_section**kappa) +\n",
    "            quad(non_shearable_integrand, critical_length, 1000, args=(phi_function,))[0]) / mean_length\n",
    "\n",
    "    # Compute number density of precipitate-based obstacles per slip plane\n",
    "    obstacle_density = (np.sqrt(3) / 3) * mean_length * rho\n",
    "\n",
    "    # Compute precipitate strengthening contribution σ_p\n",
    "    sigma_p = taylor_factor * tau_p(alpha_p, shear_modulus, burgers_vector, obstacle_density, f_bar)\n",
    "\n",
    "    # Debug print\n",
    "    print(f\"σ_p: {sigma_p:.2f} MPa, f_bar: {f_bar:.4f}, Obstacle density: {obstacle_density:.4f}\")\n",
    "\n",
    "    if sigma_p <= 0:\n",
    "        raise ValueError(f\"Error: σ_p = {sigma_p:.2f} MPa. Check f_bar ({f_bar:.4f}) and obstacle_density ({obstacle_density:.4f}).\")\n",
    "\n",
    "    # Compute final yield strength (no calibration)\n",
    "    # May need to add some form of calibration\n",
    "    yield_strength = sigma_p + solid_solution_strength + base_strength\n",
    "\n",
    "    print(f\"Yield Strength: {yield_strength:.2f} MPa\")\n",
    "\n",
    "    return yield_strength\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number density [#/nm^3]:  3.499877371019764e-05\n",
      "Solid Fraction: 0.815947%\n",
      "Weight % in Solution - Mg: 0.384, Si: 0.689, Cu: 0.000\n",
      "Solid Solution Strengthening: 67.06 MPa\n",
      "σ_p: 326.64 MPa, f_bar: 1.0002, Obstacle density: 0.0004\n",
      "Yield Strength: 403.71 MPa\n",
      "Yield Strength: 403.71 MPa\n",
      "Estimated Vickers Hardness (HV): 134.57 MPa\n"
     ]
    }
   ],
   "source": [
    "# Compute aspect ratio parameters\n",
    "aspect_ratio_params = fit_omega(precipitate_lengths, np.array(precipitate_lengths) / np.sqrt(mean_cross))\n",
    "\n",
    "rho = convert_2D_to_3D_number_density(number_density, t, mean_length)\n",
    "print('Number density [#/nm^3]: ', rho)\n",
    "volume_fraction = calculate_volume_fraction(rho, mean_cross, mean_length)\n",
    "\n",
    "alloy_composition = {'Mg': 0.70, 'Si': 0.85, 'Cu': 0.0, 'Fe': 0.150, 'Mn': 0.10, 'Cr': 0.0} # Found in SumAL\n",
    "atomic_weights = {'Al': 26.982, 'Mg': 24.305, 'Si': 28.085, 'Cu': 63.546, 'Fe': 55.845, 'Mn': 54.938, 'Cr': 51.996}\n",
    "strengthening_coefficients = {'Mg': 29.0, 'Si': 66.3, 'Cu': 46.4} # Found in Literature( reference )\n",
    "\n",
    "# Compute solid solution strengthening\n",
    "\n",
    "sigma_ss = calculate_solid_solution_strength(alloy_composition, volume_fraction, atomic_weights, strengthening_coefficients)\n",
    "print(f\"Solid Solution Strengthening: {sigma_ss:.2f} MPa\")\n",
    "\n",
    "\n",
    "# Compute solid solution strengthening\n",
    "\n",
    "# Compute yield strength for a single condition\n",
    "yield_strength = calculate_yield_strength_single(\n",
    "    precipitate_lengths=precipitate_lengths,\n",
    "    mean_length=mean_length,\n",
    "    mean_cross_section= mean_cross,\n",
    "    rho= rho,\n",
    "    aspect_ratio_params=aspect_ratio_params,\n",
    "    critical_cross_section= crit_cs,\n",
    "    kappa=1.5,\n",
    "    shear_modulus=G,\n",
    "    burgers_vector=b,\n",
    "    taylor_factor=M,\n",
    "    solid_solution_strength=sigma_ss,\n",
    "    base_strength=10,\n",
    "    omega_func=omega,\n",
    "    shearable_integrand=shearable_precipitate_integrand,\n",
    "    non_shearable_integrand=non_shearable_precipitate_integrand\n",
    ")\n",
    "\n",
    "print(f\"Yield Strength: {yield_strength:.2f} MPa\")\n",
    "hardness_hv = yield_strength / 3\n",
    "print(f\"Estimated Vickers Hardness (HV): {hardness_hv:.2f} MPa\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
