{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Strength Model\n",
    "This code uses the Holmedal model to calculate the total yield strength of 6xxx aluminium alloys.\n",
    "This strength model is here used on alloy conditions from the  SumAl project. See explanatory comments throughout the code.\n",
    "In this notebook the alloy composition of the alloys in the SumAl project is given in the code, but can easily be changed to contain other alloys as well. A Dark field, length and cross section statistics file is read by the program. The format of the of these .csv files can be found in the \"examples\" folder. One can also easily substitute the implementation to give the preceipitate distribution and statistics in another way. Lastly there is a thickness excel file that is also read by the program. The file can be found in the \"examples\" folder. This file contains the corresponding thickness of the sample contained in the dark field images for the alloys. This is needed to correctly calculate the number density of precipitates.\n",
    "\n",
    "This code uses the Holmedal model to calculate the total yield strength of 6xxx aluminium alloys.\n",
    "It is applied here to alloy conditions from the SumAl project. See the explanatory comments throughout the code.\n",
    "\n",
    "In this notebook, the alloy compositions from the SumAl project are defined directly in the code but can easily be modified to include other alloys.\n",
    "\n",
    "The program reads .csv files containing statistics from dark field images, including precipitate length and cross section. The expected file format can be found in the \"examples\" folder. The implementation can also be adapted to accept precipitate distributions and statistics from other sources.\n",
    "\n",
    "The program also reads a thickness file in Excel format (.xlsx), which is stored in the \"examples\" folder. This file contains the sample thicknesses corresponding to the dark field images for each alloy. These values are required to accurately calculate the number density of precipitates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openpyxl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.optimize import least_squares\n",
    "from scipy import special\n",
    "from scipy.integrate import quad\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Obstacle Strength Exponent (kappa)\n",
    "# -----------------------------------------------------------------------------\n",
    "# The parameter kappa (Œ∫) describes how the pinning force of shearable\n",
    "# precipitates evolves with increasing precipitate size. Following Hell et al.\n",
    "# (2023), we assume that the pinning force scales with cross-sectional area,\n",
    "# and set Œ∫ = 1. This defines how quickly the obstacle strength f approaches 1\n",
    "# as the precipitate grows beyond the critical cross-section a_c.\n",
    "# -----------------------------------------------------------------------------\n",
    "kappa = 1.0  # Obstacle strength exponent, consistent with Hell 2023\n",
    "\n",
    "M = 2.7         # Taylor factor\n",
    "G = 27E3        # [MPa] Shear modulus Al matrix\n",
    "b = 0.286       # [nm] Burgers vector Al, b = a/sqrt(2)\n",
    "#t = 49.52      # var4_DAA [nm] Sample thickness, HAS TO BE GIVEN.\n",
    "#t = 38.88       # var7_NA\n",
    "# -----------------------------------------------------------------------------\n",
    "# Precipitate Scaling Factor (alpha_p)\n",
    "# -----------------------------------------------------------------------------\n",
    "# The parameter alpha_p is a dimensionless scaling factor in the Holmedal model\n",
    "# that accounts for non-ideal interactions between dislocations and precipitates.\n",
    "\n",
    "# Following the approach in Hell 2023, we calibrate alpha_p for one known alloy\n",
    "# condition to match the model-predicted yield strength to\n",
    "# the corresponding experimental value. This calibrated value is then kept constant\n",
    "# and used across all other alloy variants and aging conditions to ensure consistency.\n",
    "#\n",
    "# Reference: Hell et al., 2023, Equation (11) and Discussion section\n",
    "# -----------------------------------------------------------------------------\n",
    "alpha_p = 0.57  # Calibrated scaling factor from one known condition (var6_NA_5h185C), should be around 0.6 from Hell 2023\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "First run the percipitate statistics models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758\n",
      "18.05\n",
      "355\n",
      "var7_PB\n",
      "[69.20576841 71.05011493 62.8381893  66.37877226 80.7729736  66.97615236\n",
      " 63.07870895 65.75766951 65.05185366 62.07801029]\n",
      "[0.0019698, 0.0026636, 0.0022782, 0.0026122, 0.0026293, 0.0024923, 0.0023296, 0.0021925, 0.0021069, 0.0021754]\n",
      "Critical Cross Section [nm]:  4.9\n"
     ]
    }
   ],
   "source": [
    "lengths_file = \"var7_PB_statistics_length.csv\"\n",
    "df_length = pd.read_csv(lengths_file)\n",
    "length_col = [col for col in df_length.columns if \"Length\" in col]\n",
    "precipitate_lengths = df_length[length_col[0]].dropna().tolist()\n",
    "mean_col_l = [col for col in df_length.columns if \"Average\" in col]\n",
    "mean_length = df_length[mean_col_l[0]].dropna().iloc[0]\n",
    "print(len(precipitate_lengths))\n",
    "print(mean_length)\n",
    "\n",
    "\n",
    "cross_section_file = \"var7_PB_statistics_cross.csv\"\n",
    "df_cross = pd.read_csv(cross_section_file)\n",
    "cross_col = [col for col in df_cross.columns if \"Cross section\" in col]\n",
    "precipitate_cross = df_cross[cross_col[0]].dropna().tolist()\n",
    "mean_col_c = [col for col in df_cross.columns if \"Average\" in col]\n",
    "mean_cross = df_cross[mean_col_c[0]].dropna().iloc[0]\n",
    "print(len(precipitate_cross))\n",
    "means_per_image_col = [col for col in df_cross.columns if \"Mean per image\" in col]\n",
    "means_per_image = df_cross[means_per_image_col[0]].dropna().tolist()\n",
    "\n",
    "\n",
    "\n",
    "dark_field_file = \"var7_PB_statistics_df.csv\"\n",
    "df_cross_dark = pd.read_csv(dark_field_file)\n",
    "density_col = [col for col in df_cross_dark.columns if \"Number Density [nm^-2]\" in col]\n",
    "number_density = df_cross_dark[density_col[0]].dropna().tolist()\n",
    "\n",
    "thickness_path = \"thickness_samples.xlsx\"\n",
    "df = pd.read_excel(thickness_path)\n",
    "\n",
    "if 'NA' in dark_field_file or 'PB' in dark_field_file:\n",
    "    target_header = dark_field_file[:7]\n",
    "else:\n",
    "    target_header = dark_field_file[:8]\n",
    "\n",
    "print(target_header)\n",
    "\n",
    "\n",
    "thickness_col = [col for col in df.columns if target_header in col]\n",
    "thickness_array = df[thickness_col[0]].dropna().to_numpy(dtype=float)\n",
    "print(thickness_array)\n",
    "print(number_density)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Critical Cross-Section Area (a_c)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# We set the critical cross section area to the mean cross section if our measurede cross\n",
    "# sections since we are always calculating the strength of peak aged conditions.\n",
    "# This is in in alignment with Hell 2023 where he smallest measured ùëé_ùëöùëíùëéùëõ found at peak\n",
    "# strength is used in the calculations.\n",
    "\n",
    "# Reference: Hell et al., 2023, Table 6\n",
    "# -----------------------------------------------------------------------------\n",
    "crit_cs = np.min(means_per_image)  # [nm¬≤] critical cross-section from Hell 2023\n",
    "print(\"Critical Cross Section [nm]: \", crit_cs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2D_to_3D_number_density(N_per_A, t, mean_length):\n",
    "    \"\"\"\n",
    "    Converts 2D number density (precipitates per nm¬≤) into 3D number density (precipitates per nm¬≥).\n",
    "\n",
    "    Parameters:\n",
    "    N_per_A (float): Precipitate count per unit area [#/nm¬≤] for each image of an alloy conditon.\n",
    "    t (float): Sample thickness [nm] of each image.\n",
    "    l_mean (float): Mean precipitate length [nm].\n",
    "\n",
    "    Returns:\n",
    "    float: 3D number density [#/nm¬≥].\n",
    "    \"\"\"\n",
    "    density = []\n",
    "    for i in range(len(t)):\n",
    "        value = (3 * N_per_A[i]) / (t[i] * (1 + (mean_length / t[i])))\n",
    "        density.append(value)\n",
    "\n",
    "\n",
    "    return np.mean(np.array(density))\n",
    "\n",
    "def calculate_volume_fraction(rho, mean_cross, mean_length):\n",
    "    \"\"\"\n",
    "    Computes the precipitate volume fraction.\n",
    "\n",
    "    Parameters:\n",
    "    rho (float): Precipitate number density [#/nm¬≥].\n",
    "    a_mean (float): Mean precipitate cross-sectional area [nm¬≤].\n",
    "    l_mean (float): Mean precipitate length [nm].\n",
    "\n",
    "    Returns:\n",
    "    float: Volume fraction f_V in precentage.\n",
    "    \"\"\"\n",
    "    return rho * mean_cross * mean_length\n",
    "\n",
    "\n",
    "\n",
    "def omega(x: list, l):\n",
    "    \"\"\"\n",
    "    Computes the aspect ratio function, modeled using a power law:\n",
    "\n",
    "        Œ©(l) = a * l^b\n",
    "\n",
    "    where:\n",
    "        - Œ©(l) is the aspect ratio of the precipitate.\n",
    "        - 'a' (x[0]) is the scaling factor.\n",
    "        - 'b' (x[1]) is the exponent.\n",
    "        - 'l' is the precipitate length (scalar or array).\n",
    "\n",
    "    The theoretical aspect ratio for a cylindrical precipitate is:\n",
    "\n",
    "        Œ© = l / sqrt(A)\n",
    "\n",
    "    Instead of using this directly, we approximate the aspect ratio using a power-law function.\n",
    "\n",
    "    To avoid values below 1, we enforce Œ©(l) ‚â• 1.\n",
    "    \"\"\"\n",
    "    arr = x[0] * np.power(l, x[1])  # Compute the power law function\n",
    "\n",
    "    # Ensure all values in arr are at least 1\n",
    "    if isinstance(arr, np.ndarray):  \n",
    "        arr[arr < 1] = 1  \n",
    "    else:  \n",
    "        arr = max(arr, 1)  # Ensures scalars do not fall below 1\n",
    "\n",
    "    return arr\n",
    "\n",
    "def fit_omega(l, aspect_ratio):\n",
    "    \"\"\"\n",
    "    Finds the best fit for the aspect ratio function Œ©(l) = a * l^b.\n",
    "    \n",
    "    l: Array of measured precipitate lengths\n",
    "    aspect_ratio: Corresponding measured aspect ratios (l / sqrt(A))?\n",
    "\n",
    "    Returns optimized values of a and b.\n",
    "    \"\"\"\n",
    "    x0_fit = [0.7, 0.7]  # Initial guess for parameters (a, b)\n",
    "    residual = lambda x: aspect_ratio - omega(x, l)  # Residual function\n",
    "    result = least_squares(residual, x0_fit)  # Perform least-squares optimization\n",
    "    return result.x  # Return fitted parameters\n",
    "\n",
    "def tau_p(alpha_p, G, b, n_p, f_bar):\n",
    "    \"\"\"\n",
    "    Strength contribution from precipitate-based obstacles.\n",
    "\n",
    "    Input:\n",
    "        alpha_p : Scaling factor\n",
    "        G       : Shear modulus [MPa]\n",
    "        b       : Burgers vector [nm]\n",
    "        n_p     : Number density of precipitate-based obstacles per slip plane [#/nm¬≤]\n",
    "        f_bar   : Mean obstacle length (dimensionless)\n",
    "\n",
    "    Output:\n",
    "        tau_p   : Strength contribution from obstacles [MPa]\n",
    "    \"\"\"\n",
    "    return alpha_p * G * b * np.sqrt(n_p) * f_bar**(3/2) * (1 - 1/6 * f_bar**5)\n",
    "\n",
    "def phi_tilde(l: float, lengths_data: float, h: float):\n",
    "    \"\"\"\n",
    "    Uncorrected distribution of precipitate lengths.\n",
    "\n",
    "    Input:\n",
    "        l  : The length interval to evaluate the distribution of lengths at\n",
    "        lengths_data : Precipitate length data used to fit the distribution\n",
    "        h  : Kernel bandwidth for smoothing, determined using Scott's rule\n",
    "\n",
    "    Output:\n",
    "        Probability density at length l (before correction)\n",
    "    \"\"\"\n",
    "    return (1 / len(lengths_data)) * np.sum(\n",
    "    np.sqrt(2) * np.exp(-0.5 * ((np.full(len(lengths_data), l) - np.array(lengths_data)) / h) ** 2) /\n",
    "    ((1 + special.erf(np.array(lengths_data) / (np.sqrt(2) * h))) * h * np.sqrt(np.pi))\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def phi(l, length_data, h):\n",
    "    \"\"\"\n",
    "    Normalized precipitate length distribution.\n",
    "\n",
    "    This function corrects the unnormalized kernel density estimate \n",
    "    phi_tilde, ensuring that the precipitate length distribution meets \n",
    "    the required boundary condition, reaching zero at l = 0.\n",
    "\n",
    "    Input:\n",
    "        l           : The length interval to evaluate the distribution of lengths at\n",
    "        length_data : Array of measured precipitate lengths\n",
    "        h           : Kernel bandwidth for smoothing, determined using Scott's rule\n",
    "\n",
    "    Output:\n",
    "        phi         : Normalized probability density of precipitate lengths [1/nm]\n",
    "\n",
    "    \"\"\"\n",
    "    return (phi_tilde(l, length_data, h) - phi_tilde(0, length_data, h) * np.exp(-0.5 * (l / h) ** 2)) / \\\n",
    "           (1 - 0.5 * h * np.sqrt(2 * np.pi) * phi_tilde(0, length_data, h))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculated_kernel_bandwidth(length_data):\n",
    "    \"\"\"\n",
    "    Computes the kernel bandwidth (h) for a single experimental condition \n",
    "    using Scott's rule:\n",
    "\n",
    "        h ‚âà d * N_l^(-0.2) * sigma_l\n",
    "\n",
    "    where:\n",
    "        - h      : Kernel bandwidth for KDE smoothing [nm]\n",
    "        - d      : Empirical scaling factor (0.8)\n",
    "        - N_l    : Number of measured precipitate lengths\n",
    "        - sigma_l: Standard deviation of precipitate lengths\n",
    "\n",
    "    Input:\n",
    "        length_data : List or array of measured precipitate length values.\n",
    "\n",
    "    Output:\n",
    "        h          : Calculated bandwidth (h) for the given condition.\n",
    "    \"\"\"\n",
    "    sigma = np.std(length_data)  # Compute standard deviation (œÉ_l)\n",
    "    N_l = len(length_data)       # Get number of data points (N_l)\n",
    "\n",
    "    # Apply Scott's rule: h = d * N_l^(-0.2) * œÉ_l\n",
    "    h = 0.8 * N_l**(-0.2) * sigma\n",
    "\n",
    "    return h  # Return the bandwidth value\n",
    "\n",
    "\n",
    "\n",
    "def shearable_precipitate_integrand(l, aspect_ratio_params, kappa, length_distribution):\n",
    "    \"\"\"\n",
    "    Computes the integrand for the shearable precipitate contribution.\n",
    "\n",
    "    Based on the integral term:\n",
    "        ‚à´ (l^(2Œ∫+1) / Œ©(l)^(2Œ∫)) * œÜ(l) dl\n",
    "\n",
    "    where:\n",
    "        - l                   : Precipitate length [nm]\n",
    "        - aspect_ratio_params  : Parameters for the aspect ratio function Œ©(l)\n",
    "        - kappa               : Scaling exponent for strength model\n",
    "        - length_distribution : Normalized precipitate length distribution œÜ(l)\n",
    "\n",
    "    Output:\n",
    "        Contribution of shearable precipitates to the mean obstacle strength.\n",
    "    \"\"\"\n",
    "    return (l**(2*kappa + 1) / omega(aspect_ratio_params, l)**(2*kappa)) * length_distribution(l)\n",
    "\n",
    "def non_shearable_precipitate_integrand(l, length_distribution):\n",
    "    \"\"\"\n",
    "    Computes the integrand for the non-shearable precipitate contribution.\n",
    "\n",
    "    Based on the integral term:\n",
    "        ‚à´ l * œÜ(l) dl\n",
    "\n",
    "    where:\n",
    "        - l                   : Precipitate length [nm]\n",
    "        - length_distribution : Normalized precipitate length distribution œÜ(l)\n",
    "\n",
    "    Output:\n",
    "        Contribution of non-shearable precipitates to the mean obstacle strength.\n",
    "    \"\"\"\n",
    "    return l * length_distribution(l)\n",
    "\n",
    "\n",
    "def convert_weight_to_atomic_fraction(weight_percent, atomic_weights, element):\n",
    "    \"\"\"\n",
    "    Convert weight percent (wt%) to atomic fraction (at%).\n",
    "\n",
    "    Input:\n",
    "        weight_percent  : Dictionary containing element weight fractions {Element: wt%}\n",
    "        atomic_weights  : Dictionary containing atomic weights {Element: atomic weight}\n",
    "        element         : Element to convert\n",
    "\n",
    "    Output:\n",
    "        atomic_fraction : Atomic fraction (at%) of the element\n",
    "    \"\"\"\n",
    "    return (weight_percent[element] / atomic_weights[element]) / \\\n",
    "           sum(weight_percent[el] / atomic_weights[el] for el in weight_percent if el in atomic_weights)\n",
    "\n",
    "\n",
    "def convert_atomic_to_weight_fraction(atomic_fraction_dict, atomic_weights, element):\n",
    "    \"\"\"\n",
    "    Convert atomic fraction (at%) to weight percent (wt%).\n",
    "\n",
    "    Input:\n",
    "        atomic_fraction_dict : Dictionary containing atomic fractions {Element: at%}\n",
    "        atomic_weights       : Dictionary containing atomic weights {Element: atomic weight}\n",
    "        element              : The specific element to convert\n",
    "\n",
    "    Output:\n",
    "        weight_percent       : Weight percent (wt%) of the specified element\n",
    "    \"\"\"\n",
    " \n",
    "\n",
    "    # Compute weight fraction using weight-to-atomic conversion for the denominator\n",
    "    return (atomic_fraction_dict[element] * atomic_weights[element]) / \\\n",
    "           sum(convert_weight_to_atomic_fraction(atomic_fraction_dict, atomic_weights, el) * atomic_weights[el] \n",
    "               for el in atomic_fraction_dict if el in atomic_weights)\n",
    "\n",
    "\n",
    "# Critical cross section is here just taken to be the mean cross section. It should be\n",
    "# the mean cross section at peak at the ageing condition near peak strength.\n",
    "def calculate_solid_solution_strength(alloy_composition, volume_fraction, atomic_weights, strengthening_coefficients):\n",
    "    \"\"\"\n",
    "    Computes the solid solution strengthening contribution from alloying elements.\n",
    "\n",
    "    Input:\n",
    "        alloy_composition         : Dictionary containing element weight fractions {Element: wt%}\n",
    "        volume_fraction           : Precipitate volume fraction (percentage, not decimal)\n",
    "        atomic_weights            : Dictionary containing atomic weights {Element: atomic weight}\n",
    "        strengthening_coefficients: Dictionary of strengthening coefficients {Element: MPa}\n",
    "\n",
    "    Output:\n",
    "        sigma_ss                  : Solid solution strengthening contribution [MPa]\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Convert volume fraction to solid fraction using unit cell ratios (œÅŒ≤''/œÅ_Al)\n",
    "    solid_fraction = (volume_fraction / 100) * (1826 / 2005)\n",
    "    print(f\"Solid Fraction: {solid_fraction * 100:.4f}%\")\n",
    "\n",
    "    # Step 2: Atomic fractions in Œ≤'' (from Ninive et al.)\n",
    "    betaDP = {\n",
    "        'Mg': 0.353,\n",
    "        'Al': 0.265,\n",
    "        'Si': 0.353,\n",
    "        'Cu': 0.029\n",
    "    }\n",
    "\n",
    "    # Step 3: Get atomic fraction of each element that precipitates out\n",
    "    precipitated_atomic = {\n",
    "        el: betaDP[el] * solid_fraction for el in ['Mg', 'Si', 'Cu']\n",
    "    }\n",
    "\n",
    "    # Step 4: Convert these atomic fractions to unnormalized weight %\n",
    "    precipitated_weights = {\n",
    "        el: precipitated_atomic[el] * atomic_weights[el] for el in precipitated_atomic\n",
    "    }\n",
    "\n",
    "    # Step 5: Subtract from original alloy composition\n",
    "    weight_mg = max(0, alloy_composition['Mg'] - precipitated_weights['Mg'])\n",
    "    weight_si = max(0, alloy_composition['Si'] - precipitated_weights['Si'])\n",
    "    weight_cu = max(0, alloy_composition['Cu'] - precipitated_weights['Cu'])\n",
    "\n",
    "    print(f\"Weight % in Solution - Mg: {weight_mg:.3f}, Si: {weight_si:.3f}, Cu: {weight_cu:.3f}\")\n",
    "\n",
    "    # Step 6: Compute solid solution strengthening using power-law from literature\n",
    "    sigma_ss = (\n",
    "        strengthening_coefficients['Mg'] * weight_mg**(2/3) +\n",
    "        strengthening_coefficients['Si'] * weight_si**(2/3) +\n",
    "        strengthening_coefficients['Cu'] * weight_cu**(2/3)\n",
    "    )\n",
    "\n",
    "    return sigma_ss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_yield_strength(precipitate_lengths, mean_length,\n",
    "                                    rho, aspect_ratio_params, critical_cross_section, \n",
    "                                    kappa, shear_modulus, burgers_vector, taylor_factor, \n",
    "                                    solid_solution_strength, base_strength,\n",
    "                                    omega_func, shearable_integrand, non_shearable_integrand):\n",
    "    \"\"\"\n",
    "    Computes the yield strength for a single alloy condition **without empirical calibration**.\n",
    "\n",
    "    Input:\n",
    "        precipitate_lengths      : List of precipitate lengths for the alloy condition [nm]\n",
    "        mean_length              : Mean precipitate length in this condition [nm]\n",
    "        rho                      : Number density of precipitates in this condition [#/nm¬≥]\n",
    "        aspect_ratio_params      : Parameters for the aspect ratio function Œ©(l)\n",
    "        critical_cross_section   : Critical cross-section a_c defining shearable/non-shearable transition [nm¬≤]\n",
    "        kappa                   : Scaling exponent for strength model\n",
    "        shear_modulus            : Shear modulus G [MPa]\n",
    "        burgers_vector           : Burgers vector b [nm]\n",
    "        taylor_factor            : Taylor factor M (polycrystalline strengthening factor)\n",
    "        solid_solution_strength  : Solid solution strengthening contribution [MPa]\n",
    "        base_strength            : Baseline yield strength œÉ‚ÇÄ [MPa]\n",
    "        omega_func               : Function to compute aspect ratio Œ©(l)\n",
    "        shearable_integrand      : Function computing the integral for shearable precipitates\n",
    "        non_shearable_integrand  : Function computing the integral for non-shearable precipitates\n",
    "\n",
    "    Output:\n",
    "        yield_strength           : Computed yield strength [MPa]\n",
    "    \"\"\"\n",
    "\n",
    "    # Solve for the critical length l_c using least squares\n",
    "    residual_func = lambda l: np.sqrt(critical_cross_section) * omega_func(aspect_ratio_params, l) - l\n",
    "    critical_length = least_squares(residual_func, 16).x[0]  \n",
    "\n",
    "    # Compute kernel bandwidth for KDE smoothing\n",
    "    kernel_bandwidth = calculated_kernel_bandwidth(precipitate_lengths)\n",
    "\n",
    "    # Define phi with proper arguments so it can be used inside quad()\n",
    "    phi_function = lambda l: phi(l, precipitate_lengths, kernel_bandwidth)\n",
    "\n",
    "    # Compute mean obstacle strength f_bar\n",
    "    f_bar = (quad(shearable_integrand, 0, critical_length, args=(aspect_ratio_params, kappa, phi_function))[0] / (critical_cross_section**kappa) +\n",
    "            quad(non_shearable_integrand, critical_length, 1000, args=(phi_function,))[0]) / mean_length\n",
    "\n",
    "    # Compute number density of precipitate-based obstacles per slip plane\n",
    "    obstacle_density = (np.sqrt(3) / 3) * mean_length * rho\n",
    "\n",
    "    # Compute precipitate strengthening contribution œÉ_p\n",
    "    sigma_p = taylor_factor * tau_p(alpha_p, shear_modulus, burgers_vector, obstacle_density, f_bar)\n",
    "\n",
    "    # Debug print\n",
    "    print(f\"œÉ_p: {sigma_p:.2f} MPa, f_bar: {f_bar:.4f}, Obstacle density: {obstacle_density:.4f}\")\n",
    "\n",
    "    if sigma_p <= 0:\n",
    "        raise ValueError(f\"Error: œÉ_p = {sigma_p:.2f} MPa. Check f_bar ({f_bar:.4f}) and obstacle_density ({obstacle_density:.4f}).\")\n",
    "\n",
    "    # Compute final yield strength (no calibration)\n",
    "    # May need to add some form of calibration\n",
    "    yield_strength = sigma_p + solid_solution_strength + base_strength\n",
    "\n",
    "    print(f\"Yield Strength: {yield_strength:.2f} MPa\")\n",
    "\n",
    "    return yield_strength\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number density [#/nm^3]: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8.246115777954009e-05\n",
      "Solid Fraction: 0.0091%\n",
      "Weight % in Solution - Mg: 0.699, Si: 0.849, Cu: 0.350\n",
      "Solid Solution Strengthening: 105.33 MPa\n",
      "œÉ_p: 290.32 MPa, f_bar: 1.0000, Obstacle density: 0.0009\n",
      "Yield Strength: 405.65 MPa\n",
      "Yield Strength: 405.65 MPa\n",
      "Estimated Vickers Hardness (HV): 135.22 MPa\n"
     ]
    }
   ],
   "source": [
    "# Compute aspect ratio parameters\n",
    "aspect_ratio_params = fit_omega(precipitate_lengths, np.array(precipitate_lengths) / np.sqrt(mean_cross))\n",
    "\n",
    "rho = convert_2D_to_3D_number_density(number_density, thickness_array, mean_length)\n",
    "print('Number density [#/nm^3]: ', rho)\n",
    "volume_fraction = calculate_volume_fraction(rho, mean_cross, mean_length)\n",
    "\n",
    "alloy_compositions = {\n",
    "    'var1': {'Mg': 0.700, 'Si': 0.850, 'Zn': 0.000, 'Cu': 0.100, 'Mn': 0.100, 'Fe': 0.150},\n",
    "    'var2': {'Mg': 0.700, 'Si': 0.850, 'Zn': 0.000, 'Cu': 0.200, 'Mn': 0.100, 'Fe': 0.150},\n",
    "    'var3': {'Mg': 0.700, 'Si': 0.850, 'Zn': 0.000, 'Cu': 0.350, 'Mn': 0.100, 'Fe': 0.150},\n",
    "    'var4': {'Mg': 0.700, 'Si': 0.850, 'Zn': 0.000, 'Cu': 0.000, 'Mn': 0.250, 'Fe': 0.150},\n",
    "    'var5': {'Mg': 0.700, 'Si': 0.850, 'Zn': 0.000, 'Cu': 0.200, 'Mn': 0.250, 'Fe': 0.150},\n",
    "    'var6': {'Mg': 0.700, 'Si': 0.850, 'Zn': 0.000, 'Cu': 0.350, 'Mn': 0.250, 'Fe': 0.150},\n",
    "    'var7': {'Mg': 0.700, 'Si': 0.850, 'Zn': 0.000, 'Cu': 0.350, 'Mn': 0.350, 'Fe': 0.150},\n",
    "    'var8': {'Mg': 0.700, 'Si': 0.850, 'Zn': 0.000, 'Cu': 0.600, 'Mn': 0.250, 'Fe': 0.150}\n",
    "}\n",
    "# Found in SumAL\n",
    "alloy_composition = alloy_compositions[dark_field_file[:4]]\n",
    "\n",
    "atomic_weights = {'Al': 26.982, 'Mg': 24.305, 'Si': 28.085, 'Cu': 63.546, 'Fe': 55.845, 'Mn': 54.938, 'Cr': 51.996}\n",
    "strengthening_coefficients = {'Mg': 29.0, 'Si': 66.3, 'Cu': 46.4} # Found in Literature(https://www.sciencedirect.com/science/article/pii/S0921509321017615?via%3Dihub)\n",
    "\n",
    "# Compute solid solution strengthening\n",
    "\n",
    "sigma_ss = calculate_solid_solution_strength(alloy_composition, volume_fraction, atomic_weights, strengthening_coefficients)\n",
    "print(f\"Solid Solution Strengthening: {sigma_ss:.2f} MPa\")\n",
    "\n",
    "\n",
    "# Compute solid solution strengthening\n",
    "\n",
    "# Compute yield strength for a single condition\n",
    "yield_strength = calculate_yield_strength(\n",
    "    precipitate_lengths=precipitate_lengths,\n",
    "    mean_length=mean_length,\n",
    "    rho= rho,\n",
    "    aspect_ratio_params=aspect_ratio_params,\n",
    "    critical_cross_section= crit_cs,\n",
    "    kappa=kappa,\n",
    "    shear_modulus=G,\n",
    "    burgers_vector=b,\n",
    "    taylor_factor=M,\n",
    "    solid_solution_strength=sigma_ss,\n",
    "    base_strength=10,\n",
    "    omega_func=omega,\n",
    "    shearable_integrand=shearable_precipitate_integrand,\n",
    "    non_shearable_integrand=non_shearable_precipitate_integrand\n",
    ")\n",
    "\n",
    "print(f\"Yield Strength: {yield_strength:.2f} MPa\")\n",
    "hardness_hv = yield_strength / 3\n",
    "print(f\"Estimated Vickers Hardness (HV): {hardness_hv:.2f} MPa\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
