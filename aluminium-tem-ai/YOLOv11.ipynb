{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic segmentation of precipitate statistics using YOLOv11 architecture\n",
    "\n",
    "This code utilizes a YOLOv11 deep learning architecture to automatically extract precipitate statistics from transmission electron microscopy (TEM) images. \n",
    "The code is developed as part of a master's thesis in applied physics, the code segments precipitates within the images, enabling the automatic measurement of precipitate length and cross-sections. \n",
    "By automating this process, it significantly accelerates the analysis of precipitate distributions, aiding in materials research and development.\n",
    "\n",
    "## Author:\n",
    "\n",
    "**Kristian B. Thevik** - Developed for Master thesis in Physics 2024\n",
    "\n",
    "## Note:\n",
    "\n",
    "- It is recommended to have a GPU and the CUDA-version of Pytorch installed (However it is not required).\n",
    "- Data can be loaded in two ways, either by directly uploading the .DM3 file, or converting the .DM3 to an image (.jpeg/.png) and manually selecting the calibration unit *nm_per_px*.\n",
    "- YOLOv11 documentation: https://docs.ultralytics.com/models/yolo11/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.27  Python-3.10.8 torch-2.5.1+cpu CPU (AMD Ryzen 5 3500U with Radeon Vega Mobile Gfx)\n",
      "Setup complete  (8 CPUs, 6.9 GB RAM, 208.7/237.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt5\n",
    "\n",
    "\n",
    "#%pip install --user ultralytics supervision roboflow opencv-python>=4.6.0 pandas>=1.1.4 py-cpuinfo scipy>=1.10.0 defusedxml<0.8.0,>=0.7.1 tqdm>=4.64.0\n",
    "\n",
    "\n",
    "import ultralytics\n",
    "import numpy as np\n",
    "import testMaster._dm3_lib as dm\n",
    "ultralytics.checks()\n",
    "\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv11 Model Loaded\n",
      "Prediction confidence threshold set to 0.15\n",
      "\n",
      "0: 2048x2048 252 needles, 15417.7ms\n",
      "Speed: 46.7ms preprocess, 15417.7ms inference, 10644.1ms postprocess per image at shape (1, 3, 2048, 2048)\n",
      "(2048, 2048, 3)\n",
      "Prediction confidence threshold set to 0.15\n",
      "\n",
      "0: 2048x2048 278 needles, 17055.0ms\n",
      "Speed: 70.7ms preprocess, 17055.0ms inference, 15342.0ms postprocess per image at shape (1, 3, 2048, 2048)\n",
      "(2048, 2048, 3)\n",
      "Prediction confidence threshold set to 0.15\n",
      "\n",
      "0: 2048x2048 259 needles, 16775.8ms\n",
      "Speed: 78.3ms preprocess, 16775.8ms inference, 9595.2ms postprocess per image at shape (1, 3, 2048, 2048)\n",
      "(2048, 2048, 3)\n",
      "Prediction confidence threshold set to 0.15\n",
      "\n",
      "0: 2048x2048 256 needles, 17777.6ms\n",
      "Speed: 51.1ms preprocess, 17777.6ms inference, 6833.7ms postprocess per image at shape (1, 3, 2048, 2048)\n",
      "(2048, 2048, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(model_path)\n\u001b[0;32m     21\u001b[0m yolo_evaluator \u001b[38;5;241m=\u001b[39m YOLOEvaluator(\n\u001b[0;32m     22\u001b[0m     dataset_dir \u001b[38;5;241m=\u001b[39m dataset_path,\n\u001b[0;32m     23\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m )\n\u001b[1;32m---> 29\u001b[0m \u001b[43myolo_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\masterRepo\\src\\testMaster\\DatasetEvaluator.py:58\u001b[0m, in \u001b[0;36mEvaluator.statistics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     image, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm_per_px[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDM_2_array(dm\u001b[38;5;241m.\u001b[39mDM3(image))\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m#print(self.nm_per_px[id])\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m prediction, scores, gray_img, overlay_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnm_per_px\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_image(gray_img, overlay_img, \u001b[38;5;28mid\u001b[39m)\n\u001b[0;32m     60\u001b[0m mean_val \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\Documents\\masterRepo\\src\\testMaster\\DatasetEvaluator.py:604\u001b[0m, in \u001b[0;36mYOLOEvaluator.predict\u001b[1;34m(self, img, nm_px_ratio)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(masks):\n\u001b[0;32m    603\u001b[0m     binary_mask \u001b[38;5;241m=\u001b[39m mask \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m  \n\u001b[1;32m--> 604\u001b[0m     binary_mask_np \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;66;03m# Apply erosion to make the mask thinner\u001b[39;00m\n\u001b[0;32m    607\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), np\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Using DataSetEvaluator\n",
    "from testMaster.DatasetEvaluator import YOLOEvaluator\n",
    "\n",
    "# If files in the dataset are .dm3 files, nm_per_px will be extracted automatically and replace the \n",
    "# existing nm_per_px value in the list. It works to have some files as dm3 and some as .jpg/.png.\n",
    "# Always give nm_per_px as a list with lenght equal to number of files to be evaluated. First value corresponds\n",
    "# to nm_per_px value for the first image and so on. For dm3 files an arbitrary value can be given, it will be replaced\n",
    "# either way.\n",
    "\n",
    "#nm_per_px = [0.069661] * 19 #Cross\n",
    "nm_per_px = [2.016685] * 11 #Length\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "this_dir = Path.cwd()\n",
    "dataset_path = this_dir.parent / \"data\" / \"var3_NA_5h185C_length\"\n",
    "model_path = this_dir.parent / \"data\" / \"models\" / \"yolo_length.pt\"\n",
    "model = YOLO(model_path)\n",
    "  \n",
    "\n",
    "yolo_evaluator = YOLOEvaluator(\n",
    "    dataset_dir = dataset_path,\n",
    "    model = model,\n",
    "    nm_per_px = nm_per_px,\n",
    "    type = 'length',\n",
    "    device = 'cpu'\n",
    ")\n",
    "\n",
    "yolo_evaluator.statistics()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
